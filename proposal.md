---
layout: article
title: Proposal
---

## Summary

This project will use the duckietown simulator to accomplish some of tasks laid out in the AI Driving Olympics handbook, expanded on in the goals section. A main focus of this project will be to see how to use the inputs from the simulator, (i.e. the camera and current positioning of the bot) in order to guide the movement of the virtual duckiebot. Following this, the focus will include an effective transition from the virtual duckiebot in the simulator to the movement of the real duckiebot on the physical track. This effort could guide considerations for building an effective virtual environment for a physical robot. It will also individually provide a learning experience into the real world challenges that come with the use of reinforcement learning. 

## Evaluation Plan

## Goals
Our first goal is to use one of the methods described above (deep q network, imitation learning, an ensamble of deep q networks) in order to get a duckie bot to complete the "lane following" (LF) challenge. Our second goal is to implement the other two methods and compare how well all three methods do on the LF challenge. Our third goal is to is to use the best method to complete the "lane following with dynamic vehicles" (LFV) challenge and "lane following with dynamic vehicles and intersections" (LFVI) challenge.